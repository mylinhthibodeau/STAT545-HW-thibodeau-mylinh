---
title: "hw10-manual-download"
author: "My Linh Thibodeau"
date: '2017-11-29'
output: github_document
---

```{r}
suppressMessages(suppressWarnings(library(HelpersMG)))
suppressMessages(suppressWarnings(library(coda)))
suppressMessages(suppressWarnings(library(tidyverse)))
knitr::opts_chunk$set(fig.width=12, fig.height=9)
suppressMessages(suppressWarnings(library(knitr)))
suppressMessages(suppressWarnings(library(kableExtra)))
options(knitr.table.format = "html")
```

## Introduction

There are multiple approaches to manually get web data:

1. Makefile (same commands can be used directly in the terminal of course)
	- curl
	- wget
2. RStudio - R or Rmd extension files
	- base R utils and download.file() - (example [here](https://stackoverflow.com/questions/39893056/download-file-in-r-using-wget))
	- library(HelpersMG) and wget() - (example [here]())
	- library(downloader) and download() -> this functionality is actually also available through the library(RCurl)

For additional information on ropendsci web service download, you can refer to the stat545 page [here](http://stat545.com/webdata02_activity.html)

I will illustrate the example of HelpersMG::wget() and unziping with gzfile() below.

### Part 1 - Getting flatfile type data

With the `wget()` function of HelpersMG package, we can directly download an url file. 
```{r}
wget(url = "http://www.ebi.ac.uk/gene2phenotype/downloads/DDG2P.csv.gz")
```

### Part 2 - Unzip and read to make dataframe

In this case, the file needs to be unzip the file, which can be done with the `gzfile()` function of base R connections.

```{r}
DDG2P_data <- read.table(DDG2P_gz <- gzfile("DDG2P.csv.gz"), sep=",", header = TRUE)
unlink("DDG2P.csv.gz")
```


### Part 3 - Take a look at the type of data

```{r}
head(DDG2P_data) %>% kable()
```

### For additional examples of manually downloaded web data

I will not provide additional examples of how to manually download web data flatfiles as this work has been completed in previous STAT545/547 homework assinments:

* Homework 7 - Refer to Makefile for example using curl and refer to README for example using wget for ftp data.
* Homework 8 - Code not provided, but same techniques applied to obtain the HGNC Database, HUGO Gene Nomenclature Committee (HGNC).


## THIS WORK HAS BEEN COMPLETED FOR LEARNING PURPOSES ONLY

## SOURCES OF DATA - REFERENCES

* DECIPHER: Database of Chromosomal Imbalance and Phenotype in Humans using Ensembl Resources. Firth, H.V. et al (2009). Am.J.Hum.Genet 84, 524-533 (DOI: dx.doi.org/10/1016/j.ajhg.2009.03.010). 
* This homework makes use of data generated by the DECIPHER community. A full list of centres who contributed to the generation of the data is available from http://decipher.sanger.ac.uk and via email from decipher@sanger.ac.uk. Funding for the project was provided by the Wellcome Trust.

## GENERAL REFERENCES

* stat545 webdata02 lecture 2015 [here](http://stat545.com/webdata02_activity.html)
