---
title: "stat547-hw06-thibodeau-mylinh"
output:  
pdf_document: 
    latex_engine: xelatex
---

```{r global_options, include = FALSE}
#suppressPackageStartupMessages(library(plyr))
suppressPackageStartupMessages(library(tidyverse))
suppressWarnings(library(tidyverse))
knitr::opts_chunk$set(message=FALSE, 
tidy.opts=list(width.cutoff=60)) 
suppressWarnings(suppressMessages(library(knitr)))
suppressWarnings(suppressMessages(library(kableExtra)))
#suppressWarnings(options(knitr.table.format = "markdown"))
#install.packages("webshot")
#webshot::install_phantomjs()
#install.packages("pander")
library(readr)
suppressWarnings(suppressMessages(library(forcats)))
library(purrr)
library(repurrrsive)
library(tibble)
library(stringr)
library(devtools)
library(listviewer)
library(jsonlite)
#install.packages("ontologyIndex")
library(ontologyIndex)
#install.packages("ontologySimilarity")
library(ontologySimilarity)
#install.packages("ontologyPlot") is not available (for R version 3.4.1)
#install.packages("Rgraphviz") is not available (for R version 3.4.1)
#library(ontologyPlot) # is not available (for R version 3.4.1)
#install.packages("GO.db") # is not available (for R version 3.4.1)
```

I installed these new packages of the ontologyX suite [here](https://cran.r-project.org/web/packages/ontologyIndex/vignettes/intro-to-ontologyX.html), which offer tools to explore ontology data. 

We can use the getNamespaceExports() to see what are the functions of these packages !
```{r}
getNamespaceExports("ontologyIndex") 
getNamespaceExports("ontologySimilarity") 
```


First step, get the Human Disease Ontology as explained [here](https://github.com/DiseaseOntology/HumanDiseaseOntology/blob/master/src/ontology/README-editors.md), I had to clone the repository (which I called HumanDiseaseOntology_git, as suggested by the github README document).
```{r}
get_relation_names("HumanDiseaseOntology_git/src/ontology/HumanDO.obo")
HumanDO <- get_ontology("HumanDiseaseOntology_git/src/ontology/HumanDO.obo", propagate_relationships=c("is_a", "part_of"))
#View(HumanDO)
```

I have downloaded a basic version of the Gene Ontology (GO) at [here](http://www.geneontology.org/page/download-ontology) and I will now look into what are the relationships between the GO terms.
```{r}
get_relation_names("GO/go-basic.obo")
GO <- get_ontology("GO/go-basic.obo")
#View(GO)
str(GO, max.level = 1) %>% head() 
```

Interestingly, the ontologyIndex package does come with an R version of HPO (Human Phenotype Ontology) and GO (Gene Ontology), which you can load as follow.
```{r}
data(hpo)
#View(hpo)
data(go)
#View(go)
```
*Note.* I will try not use the R lists of the ontologyIndex, because I am trying to learn how to read and manipulate the OBO format files directly. 

# Homework instructions

**Pick (at least) two of the six (numbered) topics below and do one of the exercise prompts listed, or something comparable using your dataset of choice.**

The two tasks I picked are the following:

1. Character data
5. Work with a list

***

# 1. Character data

## Let's take a peak at the data 

For the first task, we will be exploring some character data, and we will use ontology terms for this. This examples is modelled on Daniel Greene's work [here](https://cran.r-project.org/web/packages/ontologySimilarity/vignettes/ontologySimilarity-introduction.html). 

However, I think it would be useful to try and understand the data of HumanDO a bit better first. Here are some key concepts about HumanDO:

* As opposed to the GO dataset above, HumanDO only has one type of relationship and it is "is_a"
* It is a large list of 6 elements
* These 6 elements are:
1. id: specific DOID (Disease Ontology ID) identifier
2. name: specific term attached to the identifier (e.g. angiosarcoma)
3. parents: an ontology goes from general terms (parents) to more specific terms (children)
4. children: on parent can have zero children (if it is a unique term), or many children (if it is a general term which can be further divided into more specific terms)
5. ancestors: this list keep an aggregate list of all the more general terms that preceded a term (all the parents, grand-parents, great grand-parents "terms", etc.)
6. obsolete: this is a boolean list, which includes all the terms/DOID identifiers that were once in the HumanOD ontology: most of these are currently valid ("TRUE"), but some are not in use anymore ("FALSE")

Let us look at an example. Let's look at the diseases that contain the word "encephalitis":
```{r}
head(HumanDO$name[grep(x=HumanDO$name, pattern = "encephalitis")])
```
Note. Use of grep in ontology data also from Daniel Greene's work [here](https://cran.r-project.org/web/packages/ontologyIndex/vignettes/intro-to-ontologyX.html)


***
Put in a dataframe?

***

Let's look at the diseases that contain the word "Japanese":
```{r}
HumanDO$name[grep(x=HumanDO$name, pattern = "Japanese")]
```

We note that DOID:0050050 is associated with the disease "Japanese spotted fever". Let's look at the ancestor of this term.

```{r}
get_term_property(ontology=HumanDO, property = "ancestors", term = "DOID:0050050",as_names=TRUE)
```
Note. So this is pretty intuitive when we think about it: some terms like "disease" are very general, and when the ontology tree gains more granularity, then the addition of characteristics such as "bacterial", "infectious" and "spotted fever" lead to the creation of a specific ontology disease identifier:diagnosis (DOID:0050050 = Japanese spotted fever).

***

We will use the HumanDO data and set a seed.
```{r}
set.seed(1)
```

Then, we will use the `descendants_IC()` function to calculate information content of terms based on frequency with which it is an ancestor of other terms.
```{r}
information_content <- descendants_IC(HumanDO)
```

Then, we generate 5 random sets of 8 terms.
```{r}
term_sets <- replicate(simplify=FALSE, n=5, expr=minimal_set(HumanDO, sample(HumanDO$id, size=8)))
term_sets 
```

Note that the term_sets variable is a small nested list of characters items: there are 5 lists, each of which contains one list of 8 items, as exemplified here:
```{r}
str(term_sets)
```

In genomics, it can be helpful to compare sets of terms and determine how much similarity is shared between datasets (here, we have 5 lists, or 5 "mini datasets"). We can use the `get_sim_grid()` function to produce a similarity matrix and verify if any dataset is highly similar to another one.
```{r}
similarity_matrix <- get_sim_grid(ontology= HumanDO, term_sets = term_sets)
# similarity_matrix %>% kable(format = "markdown", align="c")
similarity_matrix
```
Note. From the top-left corner to the bottom-right corner, the similarity score is always 1 because we are comparing respectively list 1 with list 1, list 2 with list 2, etc. 

***

## Let's manipulate some strings now

I will be completed the tasks of this R for Data Science tutorial [here](http://r4ds.had.co.nz/strings.html), as suggested in the homework 6 instructions.

### String basics

```{r}
string1 <- "anemia"
string2 <- 'I am looking for the word "anemia" in a list' # Using double quotes inside simple quotes

```

Using one double quote or single quote
```{r}
double_quote <- "\""
double_quote2 <- '"'
single_quote <- '\'' 
single_quote2 <- "'"
```

```{r}
double_quote
double_quote2
single_quote
single_quote2
```
Note. In the tutorial, it seems as if the backslash bar is not printed, but in the example above, it does get printed. It seems that only the use of single quotes provides us with the expected result, so I will keep this format in the future. 

Let's try to print a backslash. These all produced an error message:

* "\"
* "\\"
* "\ "

```{r}
"\ '"
```
Note. This simply does not print a backslash.

As shown in block028 of the character data stat545 website [here](http://stat545.com/block028_character-data.html), using the function cat instead of print allow us to print a backslash (or "escape")
```{r}
cat("Here is a backslash: \\ ")
```

There can be some printed representation of a string that is not the same than the string itself, and using the `writeLines()` function allows us to see the raw content:
```{r}
x <- c("one \"", "two \\")
x
writeLines(x)
```

Other handy special characters are `"\n"` (newline) and `"\t"`
```{r}
cat("We can use \n to print a new line \n\n")
cat("While \t inserts a tab")
```

Some strings actually represent non-English characters in all coding platforms, for example:
```{r}
x <- "\u00b5"
x
```

Strings can be put into a charactor vector
```{r}
c("anemia", "low iron", "pallor")
```

### String length

How many character in this string? Use str_length
```{r}
str_length(c("anemia", "low iron", "pallor"))
```
Note. White spaces count as characters.

### Combining strings

Use `str_c()`
```{r}
str_c("anemia", "low iron", "pallor")
```
Note. As mentioned, white spaces count as characters, so the white space in "low iron" is preserved here.

You can also specify the separator:
```{r}
str_c("anemia", "low iron", "pallor", sep=" = ")
```

You can specify what the missing values "NA" can be replaced with:
```{r}
x <- c("anemia",  NA)
str_c("--> ", x , " <--")
str_c("--> ", str_replace_na(x), " <--")
```

In the example, `str_c()` is vectorized, and it makes the shorter vectors the same length as the longest vector:

```{r}
str_c("prefix-", c("a", "b", "c"), "", "-suffix")
```
Note. Objects of length zero (e.g. "" above) are dropped.

This can be used with an if statement.
```{r}
cancer_type <- "breast cancer"
time_since_diagnosis <- "2 years"
day_of_diagnosis <- FALSE

str_c(
  "It has been ", time_since_diagnosis, " since your diagnosis of ", cancer_type, 
  if (day_of_diagnosis) "and I am sorry to give you this bad news today"
)
```

We can also collapse a vector of strings as followed:
```{r}
str_c(c("anemia", "low iron", "pallor"), collapse=" = ")
```

###  Subsetting strings

We can extract part of a string with `str_sub()`, and specify the inclusive positions (start and end) of the substring to extract. 

```{r}
list_of_strings <- c("dominant", "recessive", "X-linked", "mitochondrial")
str_sub(list_of_strings, 1, 4)
```

```{r}
str_sub(list_of_strings, -4, -1)
```

Even if you put "too big of a range", it will still works !
```{r}
str_sub(list_of_strings, 1, 15)
```

```{r}
str_sub(list_of_strings, -1, -1) <- str_to_upper(str_sub(list_of_strings, -1, -1))
list_of_strings
```

### Locales

Here are some functions to change the letter format:

```{r}
str_to_upper("recessive") # Change to upper case
str_to_lower("PIK3CA") # Change to lower case
str_to_title("MTOR pathway") # Capitalizes the first letter of each word
```

Locales are used to specify special characters according to the specific language. Different languages have different rules for changing case, hence the need to specify. ISO is a 639 language code, you can peak [here](http://www.loc.gov/standards/iso639-2/php/English_list.php).
```{r}
str_to_upper("i") # English
str_to_upper("i", "tr") # Turkish
```

Base R has some functions, like order() and sort() functions, which can sort strings using the current locale. But stringr functions is more consistent and flexible as it can take a locale argument. 
```{r}
list_of_strings <- c("recessive", "X-linked", "dominant",  "mitochondrial", "anticipation")
str_sort(list_of_strings, locale = "en")
str_sort(list_of_strings, locale = "haw")
```

```{r}
str_order(list_of_strings, locale = "en")
str_order(list_of_strings, locale = "haw")
```
Note. Apparently, the order can change according to the locale (language) selected, as showed [here](http://r4ds.had.co.nz/strings.html), but I must have tried a dozen languages and it never changed the order of my list. Oh well, I'll still keep it in mind just in case.

***

Exploring some functions.

*paste() and paste0()*
```{r}
paste("PIK3CA", "BRCA1", "TP53", "PTEN", "MLH1")
paste0("PIK3CA", "BRCA1", "TP53", "PTEN", "MLH1")
```
I found with this blog [here](https://www.r-bloggers.com/difference-between-paste-and-paste0/) that the difference between paste and paste0 is that their separator is " " and "" respectively.

*Get the character in the middle using str_length() and str_sub()*
```{r}
gene1 <- "BRCA1"
str_sub(gene1, ceiling(str_length(gene1)/2), ceiling(str_length(gene1)/2))
```

*Difference between sep and collapse?*

```{r}
str_c("BRCA1", "PTEN", sep = " and ") # Takes the list of strings as argument
str_c(c("BRCA1", "PTEN"), collapse = " + ") # Takes a vector as argument
```

The function str_wrap() can be used to reformat strings, but I see very little application for this function in my type of research work, so I will not illustrate it here.

str_trim() trim whitespace from start and enf of string.
```{r}
cancer_diagnoses <- str_trim(c(" breast cancer", "paraganglioma   ", "medullary thyroid cancer", "   glioblastoma", "pheochromocytoma"))
#str(cancer_diagnoses)
```

## Matching patterns with regular expressions

Find a substring to highlight with str_view()
```{r}
str_view(cancer_diagnoses, "oma")
```

A dot (".") can be used to replace any unknown character.
```{r}
str_view(cancer_diagnoses, "..oma")
```
Note. The two dots highlight the 2 characters preceeding "oma".

You have to use the escape `\\` in order to be able to search for the actual "." character in strings.
```{r}
dot <- "\\."
writeLines(dot)
str_view(c("abc", "a.c", "bef"), "a\\.c")
```

In order to look for a backslash, you need no less than 4 of them:
```{r}
x <- "a\\b"
writeLines(x)
#> a\b

str_view(x, "\\\\")
```

Why each of these strings don’t match a `\`: `"\"`, `"\\"`, `"\\\"` ?

* `"\"` : this doesn't work because the backslash is leading to an "escape" for the `"` and the expression is still open. 
* `"\\"`: this doesn't work because it literally prints `"\\"`.
* `"\\\"`: the expression is interpreted as is still open.

## Anchor

Here are some useful options as well: 

* ^ to match the start of the string.
* $ to match the end of the string.

```{r}
str_view(cancer_diagnoses, "oma$")
str_view(cancer_diagnoses, "^p")
```

```{r}
lung_cancer <- c("Non-Small Cell Lung Carcinoma", "Small Cell Lung Cancer", "Lung Carcinoid Tumor")
str_view(lung_cancer, "^Lung$") # Exact match is not found (starts with and finishes with), so it's not highlighted by this function
str_view(lung_cancer, "Lung") # Highlights all the words mathing "Lung" regardless of position of the word
```

### Replacing matched

Replace matches with new string (here, replace vowels by "*")
```{r}
str_replace(lung_cancer, "[aeiou]", "*")
str_replace_all(lung_cancer, "[aeiou]", "*")
```

Can be used for multiple replacements:
```{r}
copy_number <- c("2 copies of PTEN", "4 copies of GSK3B", "1 copy of TP53")
str_replace_all(copy_number, c("1" = "one", "2" = "two", "4" = "four"))
```

```{r}
sentences <- c("Lung cancer is largely due to tobacco smoking (active and passive).", "Sun exposure increases the risk for melanoma.", "Acute lymphoblastic leukemia is largely a diagnosis of the pediatric age group.")
sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") 
```
Note. This flips the order of the 2nd and 3rd word.

### Splitting

Let's explore str_split() function, which returns a list separated by a white space (as specified below)
```{r}
sentences %>%
  str_split(" ")
```

```{r}
"breast|brain|lung|pancreas" %>%
  str_split("\\|") %>%
  .[[1]]
```
Note. Since the vector length is one, it's easier to extract the 1st element of the list.

In a matrix, simplify = TRUE can be used:
```{r}
sentences %>%
  str_split(" ", simplify = TRUE)
```
Note. This puts the sentences in a "3 by 12" matrix, each cell containing 1 word (or nothing is the sentence is shorter than the longest sentence).
 
For example, we can isolate the word Japanese.  
```{r}
Japanese_disorders <- HumanDO$name[grep(x=HumanDO$name, pattern = "Japanese")]
Japanese_disorders %>% str_split(" ", n = 2, simplify = TRUE)
```
 
Highlights all the words or sentences using the boundary argument.
```{r}
str_view_all(Japanese_disorders, boundary("word")) 
str_view_all(Japanese_disorders, boundary("sentence")) 
```
This only takes the first element of the list.  
```{r}
str_split(Japanese_disorders, boundary("word"))[[1]]
```
 
### Find matches 

With regex() !

```{r}
encephalitis_disorders <- HumanDO$name[grep(x=HumanDO$name, pattern = "encephalitis")]
str_view(encephalitis_disorders, regex("vir"))
```
Note. This allows use to highligth words containing "vir", so here "viral" and "virus".

ignore_case = TRUE can be useful! 
```{r}
fever_disorders <- HumanDO$name[grep(x=HumanDO$name, pattern = "fever")]
str_view(fever_disorders, "rocky")
str_view(fever_disorders, regex("rocky", ignore_case = TRUE))
```
Note. In the first example, the word "Rocky" is not found because the first letter is capitalized, but using regex with ignore_case = TRUE resolves this issues.


Another useful one: multiline = TRUE allows ^ and $ to match the start and end of each line 
```{r}
x <- "BRCA1 1\nPTEN 2\nTP53 3\nBRCA2 4"
str_extract_all(x, "^BRCA")[[1]]
str_extract_all(x, regex("^BRCA", multiline = TRUE))[[1]]
```

As mentioned in the [tutorial](http://r4ds.had.co.nz/strings.html), comments = TRUE allows you to use comments and white space to make complex regular expressions more understandable. Spaces are ignored, as is everything after #. To match a literal space, you’ll need to escape it: "\\ "

If we use genomic coordinates for example, with regex, you can put optional format so that the function can accept either a specific chromosomal location or a chromosomal region range.
```{r}
genomic_position <- regex("
  (^chr)   # specify the chromosome number will be indicated
  (\\d{1}) # chromosome number
  (:)      # nomenclature
  (\\d{7}) # five numbers
  [ -]?    # optional dash (for genomic range)
  (\\d{7})?
  ", comments = TRUE)
str_match("chr1:1234567", genomic_position)
str_match("chr1:1234567-3217654", genomic_position)
```

Note. dotall = TRUE allows . to match everything, including \n.
```{r}
genomic_position2 <- regex("
  (^chr)   # specify the chromosome number will be indicated
  (\\d{1}) # chromosome number
  (.)      # nomenclature
  (\\d{7}) # five numbers
  [-]?     # optional dash (for genomic range)
  (\\d{7})?
  ", comments = TRUE,
  dotall = TRUE)
str_match("chr1:1234567", genomic_position2)
str_match("chr1:1234567-3217654", genomic_position2)
str_match("chr1*1234567-3217654", genomic_position2)
```
Note. In the example above, I replace the ":" by "." and then regardless of the character at that position, the function will take it. 

Three other options for "regex-like" tasks.

Option 1 - fixed(), the fast one, ignores all special regular expressions.

The microbenchmark package is able to evaluate how much rime expressions are taking to run. 
```{r}
#install.packages("microbenchmark")
library(microbenchmark)
microbenchmark::microbenchmark(
  fixed = str_detect(sentences, fixed("the")),
  regex = str_detect(sentences, "the"),
  times = 20
)
```
Note.1. As you can see, the fixed() function takes about twice as much time to run than regex. 
Note.2. It can not be used with non-English data. As there are often multiple ways of representing the same character, this can cause problem. For example, there are two ways to define “á”: either as a single character or as an “a” plus an accent:
```{r}
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
a1 == a2
```


Option 2 - coll()
```{r}
str_detect(a1, fixed(a2)) # Regex does not identify that the two terms are identical, because it looks at the litteral form and they are encoded differently
str_detect(a1, coll(a2)) # coll is able to identify it's the same letter 
```
Note.1. So I guess I won't be using French with regex then ;) 
Note.2. coll() though compares strings using standard collation rules, which is useful for doing case insensitive matching, and it takes a locale parameter.
```{r}
i <- c("I", "İ", "i", "ı")
i
str_subset(i, coll("i", ignore_case = TRUE)) # reads the Turkish "İ" as "I"
str_subset(i, coll("i", ignore_case = TRUE, locale = "tr")) # presents the Turkish "İ"
```

This allows you to identify your default locale (English Canada here).
```{r}
stringi::stri_locale_info()
```

The boundary argument used in str_split can also be used in the other stringr package functions. 
### Other uses of regular expressions

This function apropos() searches all objects available from the global environment, which is particularly helpful when you can't quite remember the object/function name but you know it contains a word like "replace".
```{r}
apropos("replace")
```
Note. I find it funny to see that the English language borrowed the term "apropos" from French. However, in the French language, this expression is actually written "à propos" and it can have two different meanings, as seen in the Collins dictionary [here](https://www.collinsdictionary.com/dictionary/french-english/%C3%A0-propos): "to show presence of mind, to do the right thing" or "suitably, aptly".

List all the files in the directory with dir()
```{r}
dir()
```

###  stringi

Talking of ontology, it appears that the stringi package is actually an ancestor of stringr, which was built on top of stringi. 

We can use the getNamespaceExports() to see what functions stringi has.
```{r}
library(stringi)
getNamespaceExports("stringi") %>% head()
```


```{r}
stri_join("BRCA1", "BRCA2")
stri_compare("BRCA1", "BRCA2") # the only difference between these 2 words is a position -1
stri_info() # Get the default settings used by the ICU library.
```
Note. Here, ICU stands for the International Components for Unicode, which Wikipedia [here](https://en.wikipedia.org/wiki/International_Components_for_Unicode) tells me are a set of opend source C/C++ and Java libraries. However, my brain always thinks about Intensive Care Unit (ICU) when I read it because of my clinical training ;) 

#### Wow, this took a lot of time !! Of course, not all the lines have code and I tried something different, but still, reaching 600 lines for the first part of the homework, that is a a bit intense. 

***

# 5. Work with a list

This exercise is using the GitHub GenomicDataCommons tutorial [here](https://github.com/seandavi/GenomicDataCommons#filtering) which shows a step by step process to obtain some cancer genomic data. 

The tasks completed are based on the STAT545/547 purrr tutorial (Simplifying data from a list of GitHub users) [here](https://jennybc.github.io/purrr-tutorial/ls02_map-extraction-advanced.html), the general purrr tutorial [here](https://jennybc.github.io/purrr-tutorial/index.html), the Trump tweets tutorial [here](https://jennybc.github.io/purrr-tutorial/ls08_trump-tweets.html) and the class notes from the [STAT545](http://stat545.com/syllabus.html) course this Fall 2017.

### DATA AND BASIC WRANGLING

From the [Genomic Data Commons (GDC) website](https://gdc.cancer.gov/about-gdc):

The National Cancer Institute's (NCI's) Genomic Data Commons (GDC) is a data sharing platform that promotes precision medicine in oncology. It is not just a database or a tool; it is an expandable knowledge network supporting the import and standardization of genomic and clinical data from cancer research programs.

I installed a few bioconductor packages. References: Bioconductor packages [here](https://bioconductor.org/install/#install-bioconductor-packages) and [here](https://bioconductor.org/packages/release/bioc/html/GenomicDataCommons.html), and pdf information on GenomicDataCommons [here](https://www.biorxiv.org/content/biorxiv/early/2017/04/04/117200.full.pdf).
```{r}
library(magrittr)
library(devtools)
#source("https://bioconductor.org/biocLite.R")
#biocLite(c("GenomicFeatures", "AnnotationDbi", "GenomeInfoDbData"))
#biocLite("GenomicDataCommons")
library(GenomicDataCommons)
```

```{r}
GenomicDataCommons::status()
```

```{r}
library(GenomicDataCommons)
library(magrittr)
ge_manifest = files() %>% 
    GenomicDataCommons::filter( ~ cases.project.project_id == 'TCGA-OV' &
                type == 'gene_expression') %>%
    manifest()
```

```{r}
library(BiocParallel)
register(MulticoreParam())
destdir = tempdir()
fnames = bplapply(ge_manifest$id, gdcdata,
                  destination_dir=destdir,
                  BPPARAM = MulticoreParam(progressbar=TRUE))
```
Note. At this stage, I kept having an error message as followed:

`Error: BiocParallel errors element index: 1, 2, 3, 4, 5, 6, ... first error: SSL certificate problem: Invalid certificate chain`

I have tries to troubleshoot this SSL certificate issue, but I have to give up as it took too much time.

Let's just make a simpler nested data.frame with information about the patients, diagnoses, samples, etc.
```{r}
qfiles = files() %>% 
  GenomicDataCommons::filter( ~ cases.project.project_id == 'TCGA-DLBC' &
                            type == 'gene_expression' &
                            analysis.workflow_type == 'HTSeq - Counts')
manifest_df = qfiles %>% manifest()
nrow(manifest_df)
str(manifest_df , max.level = 1)
```

Creating a data query
```{r}
pquery = projects()
presults = pquery %>% results()
```


```{r}
# total number of files of a specific type
res = files() %>% facet(c('type','data_type')) %>% aggregations()
res$type
```

Select only he gene_expression data.
```{r}
qfiles = files() %>% filter(~ type == 'gene_expression')
# here is what the filter looks like after translation
str(get_filter(qfiles))
```

```{r}
grep('pro',available_fields('files'),value=TRUE)
```

The aggregation function will group data of the same type together.
```{r}
files() %>% facet('cases.project.project_id') %>% aggregations() 
```

```{r}
files() %>% facet('cases.project.project_id') %>% aggregations()  %>% str(max.level = 1)
```

I only want o select the TCGA-DLBC subset of data.
```{r}
qfiles = files() %>% filter( ~ cases.project.project_id == 'TCGA-DLBC' & type == 'gene_expression')
str(get_filter(qfiles))
qfiles %>% count()
qfiles %>% str(max.level = 1)
```


```{r}
manifest_df = qfiles %>% manifest()
head(manifest_df)
```

```{r}
qfiles = files() %>% filter( ~ cases.project.project_id == 'TCGA-DLBC' &
                            type == 'gene_expression' &
                            analysis.workflow_type == 'HTSeq - Counts')
manifest_df = qfiles %>% manifest()
nrow(manifest_df)
```

```{r}
fnames = gdcdata(manifest_df$id[1:2],progress=FALSE)
```


***

```{r}
res = cases() %>% facet("project.project_id") %>% aggregations()
head(res)
library(ggplot2)
ggplot(res$project.project_id,aes(x = key, y = doc_count)) +
    geom_bar(stat='identity') +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

# Purrr tutorial exercises

## Part 1. Create a recursive list with multiple levels (analogous to gh_users)

In this section, I will create 3 nested recursive (d2, d4, d6) containing data information of 3 TCGA datasets (DLBC, GBM, LUAD) which all have the same format, and then I will make a list of these 3 lists called "list_d".

```{r}
d1 = cases() %>% GenomicDataCommons::filter(~ project.project_id=='TCGA-DLBC') %>%
    GenomicDataCommons::select(c(default_fields(cases()),'samples.sample_type')) %>%
    response_all()
d2 = d1 %>% results()
str(d1[1],list.len=1)
head(ids(d1))
str(d1, max.level = 1)
#View(d1)
#View(d2)
str(d2, max.level = 1)
typeof(d2)
```

```{r}
str(d2, list.len = 1)
```

I will make another nested list d4.
```{r}
d3 = cases() %>% GenomicDataCommons::filter(~ project.project_id=='TCGA-GBM') %>%
    GenomicDataCommons::select(c(default_fields(cases()),'samples.sample_type')) %>%
    response_all()
d4 = d3 %>% results()
typeof(d4)
```


```{r}
d5 = cases() %>% GenomicDataCommons::filter(~ project.project_id=='TCGA-LUAD') %>%
    GenomicDataCommons::select(c(default_fields(cases()),'samples.sample_type')) %>%
    response_all()
d6 = d5 %>% results()
typeof(d6)
```

```{r}
list_d <- list(d2, d4, d6)
typeof(list_d)
#View(list_d)
```

## Part 2. Name and position shortcuts

### For simplicity, let's start by looking at d2 only

```{r}
str(d2[[1]], list.len = 1) # This is the first list in this nested data.frame, and it the values are from "updated_datetime"
```


```{r}
map(d2, 1) 
```
Note. This provides the first element of each list in the d2 data.frame, but since there are multiple levels to the data.frame, it 

For example, if we were to manually pull out the first element of "primary_site" and "submitter_aliquot_ids", these functions illustrated below would be equivalent.
```{r}
map(d2["primary_site"], 1)
d2[["primary_site"]][[1]]
map(d2["submitter_aliquot_ids"], 1)
d2[["submitter_aliquot_ids"]][[1]]
```

### Let's move on to the recursive list_d

Let's look at the first level of our nested list_d.
```{r}
str(list_d, max.level = 1)
str(list_d[[3]], list.len = 1) # Look at the first level (updated_datetime) of the 3rd list in list_d, which is the LUAD dataset.
#list_d[[1]][c("samples")]
map(list_d[["updated_time"]][[1]], 1)
list_d[["submitter_aliquot_ids"]][[1]]
```

We can extract multiple values of the LUAD (3rd list of list_d) using map
```{r}
str(list_d[[1]][c("state", "primary_site")], max.level =1) # extract the state and primary site of the first list (TCGA-DLBC)
x <- map(list_d, `[`, c("state", "primary_site")) # extrate the state and primary site for all lists
str(x[1:2]) # shows the 1st and 2nd list attribute
```

The extract function of magrittr can also be used, which provides the same result.

```{r}
x <- map(list_d, magrittr::extract, c("state", "primary_site"))
str(x[1:2])
```

Exercise. Use your list inspection skills to determine the position of the elements named “state” and "primary_site". Map [ over the lists, requesting elements by position instead of name. "state" and "primary_site" are at position 13 and 15 respectively in each list.

```{r}
str(list_d[[1]][c(13, 15)], max.level =1) # only for TCGA-DLBC
x <- map(list_d, `[`, c(13, 15)) # for all 3 TCGA lists
str(x[1:3])
```

We can also use piping with these functions !
```{r}
list_d %>%
  map(`[`, c(13, 15)) %>%
  str()
```

## Part 3. Type-specific map

At this stage, it's worth exploring if the lists only have character data, or other types of data (e.g. numeric). We can take a quick peak:
```{r}
sapply(list_d[[1]], class) 
```
Note. It seems like at least the top levels are characters, but it is good to keep in mind that if we use specific map function. I checked if map_chr works the same here, but it received and error message (`Error: Result 1 is not a length 1 atomic vector`) because not only the list_d contains character, but it also contains vector, and therefore, using the general map() funciton is more appropriate here.

```
list_d %>%
  map_chr(`[`, c(13, 15)) %>%
  str()
```

## Part 4. Data frame output

Let's stack up some of these lists on top of each other with map_df(). 

```{r}
map_df(list_d, `[`, c(5, 13, 15))  # here I am selection the case_id, state and primary_site
```

I tried to create the same stacked up list with the explicit function, but since my elements (e.g. "case_id") are lists, I was only able to produce a data.frame with nested lists.
```{r}
library(dplyr)
library(tibble)
df_list_d <- list_d %>% {
  tibble(
      case_id = map(., "case_id"),
      state = map(., "state"),
      primary_site = map(., "primary_site"))
}
class(df_list_d)
```

## Part 5. "Repositories for each user"

So in this exercise, we are suppose to switch from gh_users to gh_repos, the latter having multiple nested lists (at least 4 levels from what I see).

I will keep the same nested object (called list_d) because although my data is less layered and smaller, there is one item (called "samples") which has a 4th level of modest size, with each sample id containing a list of 2 items: what type of sample was used for normal DNA and for cancer DNA studies.

Let's extract some specific data values:

Task: submitter_analyte_ids is the *2nd* item in each list. For each list, retrieve the *1st* sample listed in the *3rd* submitter_analyte_ids.
```{r}
list_d %>%
  map(c(2, 3, 1))
```

## Part 6. List inside a data frame

As mentioned previously, we do have a data frame with lists inside: df_list_d.

However, it would be nice to have the TCGA cancer type (DLBC, GBM, LUAD) also in that data frame. Interestingly enough, the name of the TCGA dataset is not stored anywhere in the data, so we will simply select the primary_site of cancer then.
```{r}
(primary_site_cancer <- map(list_d, c(15, 1, 1)))
(cancer_df_list_d <- list_d %>%
    set_names(primary_site_cancer) %>% 
    enframe("primary_site_cancer", "list_d"))
```

You might have noticed the presence of *S3:* preceding the list. There is actually 3 levels of information here. 
```{r}
sapply(list_d, class)
```
This is actually refering to a more advanced object in R, which I will not dive into here, but if you would like more information, please click [here](http://adv-r.had.co.nz/S3.html).

How do we create “one row’s worth” of data for one cancer dataset? How do we do that for all lists for a single cancer dataset?

Let's start with a simpler example. We will select the 3rd cancer type (LUAD = Lung adenocarcinoma) and only one element of each list submitter_analyte_ids. Then we will create a 4 rows tibble with each row representing the values corresponding to the first element of the list submitter_analyte_ids.
```{r}
one_cancer <- cancer_df_list_d$list_d[[3]]
View(one_cancer)
one_submitter_analyte_ids <- one_cancer$submitter_analyte_ids[[1]][1:3]
one_submitter_analyte_ids 
#one_cancer$submitter_analyte_ids <- one_cancer$submitter_analyte_ids[[2]][1:3]
View(one_cancer)
str(one_cancer, max.level=1)
str(one_submitter_analyte_ids, max.level = 1, list.len = 1) 
one_submitter_analyte_ids[c(1,3,4)] # We present exactly 3 submitter_analyte and the corresponding TCGA sample identifiers
map_df(one_cancer, `[`, c(1,3,4)) 
```

We can scale it up for all 3 cancer dataset (DLBC, GBM and LUAD), and see that the rows represent one single case.
```{r}
d3 <- cancer_df_list_d %>%
  mutate(cancer_info = list_d %>%
           map(. %>% map_df(`[`, c(1,3,4))))
d3$cancer_info[c(1,2,3)]
```

